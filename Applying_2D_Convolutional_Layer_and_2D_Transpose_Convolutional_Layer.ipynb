{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Welcome to this Notebook*\n",
        "\n",
        "In this notebook I will be sucessfully implementing 2d convolutional layer and 2d Transpose Convolutional Layer.\n"
      ],
      "metadata": {
        "id": "s5G4umClXSH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Libraries"
      ],
      "metadata": {
        "id": "t-hvoQq1S4qF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ph4SQ1gWOw1q"
      },
      "outputs": [],
      "source": [
        "from torch.nn import Conv2d\n",
        "from torch.nn import ConvTranspose2d\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Applying 2D Convolutional Layer and 2D Transpose Convolutional Layer with the help of OOP Concepts"
      ],
      "metadata": {
        "id": "AeNeAJ6mUPOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNetwork():\n",
        "  def __init__(self):\n",
        "    # Making five different layers as descirbed in the diagram\n",
        "    self.layer1=Conv2d(in_channels=3, out_channels=128, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer2=Conv2d(in_channels=128, out_channels=256, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer3=Conv2d(in_channels=256, out_channels=512, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer4=Conv2d(in_channels=512, out_channels=1024, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer5=Conv2d(in_channels=1024, out_channels=1, kernel_size=(4,4), padding=0, stride =2)\n",
        "  def discriminator(self,image):\n",
        "    img=self.layer1(image)\n",
        "    print(\"After first Layer size of image:\",img.shape)\n",
        "    img2=self.layer2(img)\n",
        "    print(\"After second Layer size of image:\",img2.shape)\n",
        "    img3=self.layer3(img2)\n",
        "    print(\"After third Layer size of image:\",img3.shape)\n",
        "    img4=self.layer4(img3)\n",
        "    print(\"After fourth Layer size of image:\",img4.shape)\n",
        "    img5=self.layer5(img4)\n",
        "    print(\"After fourth Layer size of image:\",img5.shape)\n"
      ],
      "metadata": {
        "id": "0t8ie5pAVOUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RevConvNetwork():\n",
        "  def __init__(self):\n",
        "    # Making five different layers as descirbed in the diagram\n",
        "    self.layer1=ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=(4,4), padding=0, stride =2)\n",
        "    self.layer2=ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer3=ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer4=ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=(4,4), padding=1, stride =2)\n",
        "    self.layer5=ConvTranspose2d(in_channels=128, out_channels=3, kernel_size=(4,4), padding=1, stride =2)\n",
        "  def generator(self,image):\n",
        "    img=self.layer1(image)\n",
        "    print(\"After first Layer size of image:\",img.shape)\n",
        "    img2=self.layer2(img)\n",
        "    print(\"After second Layer size of image:\",img2.shape)\n",
        "    img3=self.layer3(img2)\n",
        "    print(\"After third Layer size of image:\",img3.shape)\n",
        "    img4=self.layer4(img3)\n",
        "    print(\"After fourth Layer size of image:\",img4.shape)\n",
        "    img5=self.layer5(img4)\n",
        "    print(\"After fourth Layer size of image:\",img5.shape)"
      ],
      "metadata": {
        "id": "I6Zu9wA0Yu72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=torch.randn(3,64,64) #giving it a random torch\n",
        "con=ConvNetwork() # initilizing Convolutional Network\n",
        "con.discriminator(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMqzIP2cYbH5",
        "outputId": "356bc5a3-0983-4805-aa45-c3cbf0df9359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After first Layer size of image: torch.Size([128, 32, 32])\n",
            "After second Layer size of image: torch.Size([256, 16, 16])\n",
            "After third Layer size of image: torch.Size([512, 8, 8])\n",
            "After fourth Layer size of image: torch.Size([1024, 4, 4])\n",
            "After fourth Layer size of image: torch.Size([1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image2=torch.randn(100,1,1) #giving it a random torch\n",
        "revcon=RevConvNetwork() # initilizing Reverse Convolutional Network\n",
        "revcon.generator(image2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6GyS88CYdWZ",
        "outputId": "fb9244f9-be3b-4916-cd3c-576d1ea203e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After first Layer size of image: torch.Size([1024, 4, 4])\n",
            "After second Layer size of image: torch.Size([512, 8, 8])\n",
            "After third Layer size of image: torch.Size([256, 16, 16])\n",
            "After fourth Layer size of image: torch.Size([128, 32, 32])\n",
            "After fourth Layer size of image: torch.Size([3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Happy Coding:)"
      ],
      "metadata": {
        "id": "7E9mBO8iYzN6"
      }
    }
  ]
}